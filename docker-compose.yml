version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      # Add these settings
      ZOO_MAX_CLIENT_CNXNS: 100
      ZK_SERVER_HEAP: "2048"  # 2GB heap
      JVMFLAGS: "-Djute.maxbuffer=1572864000"  # 1.5GB buffer
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.2.1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Add these critical message size settings
      KAFKA_MESSAGE_MAX_BYTES: 1572864000  # 1.5GB
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 1572864000  # 1.5GB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 1572864000  # 1.5GB
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 1572864000  # 1.5GB
      # Memory settings to handle large messages
      KAFKA_HEAP_OPTS: "-Xmx4G -Xms2G"
      KAFKA_JVM_PERFORMANCE_OPTS: "-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxDirectMemorySize=4G"


  # redis:
  #   image: redis:7.0
  #   ports:
  #     - "6379:6379"

  # flink-jobmanager:
  #   image: flink:1.17
  #   ports:
  #     - "8081:8081"
  #   command: jobmanager
  #   environment:
  #     - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager

  # flink-taskmanager:
  #   image: flink:1.17
  #   depends_on:
  #     - flink-jobmanager
  #   command: taskmanager
  #   environment:
  #     - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager

  spark-master:
    image: bitnami/spark:3.4.1
    networks:
      - default
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - SPARK_MODE=master
    ports:
      - "8080:8080"

  spark-worker:
    image: bitnami/spark:3.4.1
    networks:
      - default
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8082:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    depends_on:
      - kafka

  schema-registry:
    image: confluentinc/cp-schema-registry:7.2.1
    depends_on:
      - kafka
    ports:
      - "8086:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:29092

networks:
  default:
    name: orders-streaming-network
    driver: bridge